@startuml
title 数据存储模块架构图

skinparam component {
    BackgroundColor<<Storage>> #E8F5E9
    BackgroundColor<<Cache>> #FFF9C4
    BackgroundColor<<Queue>> #F3E5F5
    BorderColor<<Storage>> #4CAF50
    BorderColor<<Cache>> #FBC02D
    BorderColor<<Queue>> #9C27B0
}

package "数据处理层" {
    [Processor\n数据处理器] as Processor
}

package "存储管理层" {
    [StorageManager\n存储管理器] as SM

    [BatchWriter\n批量写入器] <<Queue>>

    note right of SM
      StorageManager组件:
      - storageRegistry map[string]Storage
      - batchWriter *BatchWriter
      - router *StorageRouter
    end note

    note right of BatchWriter
      批量写入优化:
      - 缓冲区大小: 1000条
      - 刷新间隔: 10秒
      - Worker数量: 5个
      触发条件(满足任一):
      1. 缓冲区达到bufferSize
      2. 距上次刷新超过flushInterval
      3. 收到强制flush信号
    end note

    [StorageRouter\n存储路由器]

    note right of StorageRouter
      路由规则示例:
      - 小于1MB → PostgreSQL
      - 大于1MB → MongoDB
      - 包含binary → FileStorage
      - task_type=log → Elasticsearch
    end note
}

note as StorageInterfaceNote
  **存储插件接口 (Storage Interface)**
  定义统一的存储接口规范:
  - Name() string
  - Connect(config) error
  - Write(data) error
  - WriteBatch(batch) error
  - Close() error
  - HealthCheck() error
end note

package "存储实现层" {
    [PostgreSQLStorage] <<Storage>>
    [MongoDBStorage] <<Storage>>
    [FileStorage] <<Storage>>

    note bottom of PostgreSQLStorage
      **PostgreSQLStorage实现:**
      优化策略:
      1. 使用连接池(min=5, max=20)
      2. Prepared Statement缓存
      3. COPY协议批量导入
      4. 事务批量提交
    end note

    note bottom of MongoDBStorage
      **MongoDBStorage实现:**
      优化策略:
      1. BulkWrite批量操作
      2. 有序/无序写入可配置
      3. WriteConcern可调节
    end note

    note bottom of FileStorage
      **FileStorage实现:**
      支持格式:
      - JSON (单行/格式化)
      - CSV (带header)
      - Parquet (列式存储)
      支持压缩:
      - gzip, zstd
    end note
}

package "辅助组件" {
    [ConnectionPool]
    [RetryManager]
    [MetricsCollector] <<Cache>>

    note right of ConnectionPool
      **连接池管理:**
      - 最大连接数: 20
      - 最小连接数: 5
      - 空闲超时: 30分钟
    end note

    note right of RetryManager
      **重试策略:**
      - 最大重试: 3次
      - 退避算法: 指数退避
      - 首次延迟: 1秒
      - 最大延迟: 30秒
      **可重试错误:**
      - 网络超时
      - 连接断开
      - 死锁(PostgreSQL)
    end note

    note right of MetricsCollector
      **指标收集:**
      - 写入次数统计
      - 错误次数统计
      - 平均延迟计算
    end note
}

database "PostgreSQL" as PG
database "MongoDB" as Mongo
folder "File System" as FS
database "Redis\n写入缓存" as Redis

' 数据流
Processor --> SM: ProcessedData

SM --> BatchWriter: 添加到缓冲区

BatchWriter --> StorageRouter: 路由数据

StorageRouter --> PostgreSQLStorage: 关系型数据\n写入结构化数据
PostgreSQLStorage --> ConnectionPool: 获取连接
PostgreSQLStorage --> PG: INSERT/UPSERT

StorageRouter --> MongoDBStorage: 非关系型数据\n写入文档
MongoDBStorage --> Mongo: insertMany()

StorageRouter --> FileStorage: 文件数据\n写入文件
FileStorage --> FS: JSON/CSV/Parquet

' Redis缓存层
SM --> Redis: 缓存写入记录(去重)
Redis --> SM: 检查重复

' 异常处理
PostgreSQLStorage ..> RetryManager: 使用
MongoDBStorage ..> RetryManager: 使用
FileStorage ..> RetryManager: 使用

' 监控指标
PostgreSQLStorage --> MetricsCollector: 上报指标
MongoDBStorage --> MetricsCollector: 上报指标
FileStorage --> MetricsCollector: 上报指标

' 接口实现
Storage <|.. PostgreSQLStorage : implements
Storage <|.. MongoDBStorage : implements
Storage <|.. FileStorage : implements

' 组合关系
SM *-- BatchWriter
SM *-- StorageRouter
PostgreSQLStorage *-- ConnectionPool
MetricsCollector -up-* SM

' 数据流说明
note as N1
  数据写入流程:
  1. Processor将处理后的数据传递给StorageManager
  2. StorageManager添加到BatchWriter缓冲区
  3. BatchWriter达到阈值时触发批量写入
  4. StorageRouter根据规则选择存储目标
  5. 对应Storage执行实际写入操作
  6. 写入失败时通过RetryManager重试
  7. MetricsCollector收集写入指标
end note

' 性能优化说明
note as N2
  性能优化措施:

  **批量写入:**
  - 减少I/O次数
  - 利用数据库批量API
  - 异步写入不阻塞采集

  **连接池:**
  - 复用数据库连接
  - 减少连接开销
  - 控制并发数

  **缓存去重:**
  - Redis布隆过滤器
  - 避免重复写入
  - TTL自动过期

  **监控指标:**
  - 写入QPS
  - 错误率
  - 平均延迟
  - 缓冲区大小
end note

N1 -up- SM
N2 -down- BatchWriter

@enduml
